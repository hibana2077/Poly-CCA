下面是一份依「Plan A」撰寫與提交所需的**補充資訊 / 實驗 / 圖表清單**（含優先順序與可驗收標準）。直接按清單逐項補即可。

# 必填資訊（Methods／資料面）

* [ ] **資料與視角定義**：各 view 的來源、維度、特徵建構（例：k-mer、頻率、標準化方式）、標籤空間與類別分佈。
* [ ] **資料生成／擾動機制**：如何控制互資訊（MI）、訊噪比（SNR）、對齊程度（shuffle 比例）、樣本量範圍與步距。
* [ ] **前處理與對齊**：中心化／標準化的公式與時機（per-view or global）、缺失值處理、重複樣本處理。
* [ ] **模型細節**：CCA/Poly-CCA/MG-TCCA 的超參數（正則 λ、階數、群數、成分數）、實作庫／版本。
* [ ] **統計檢定設定**：HSIC／距離相關（dCor）核種與帶寬；置換檢定迭代數（建議 ≥1,000）；多重比較校正（Holm–Bonferroni）。
* [ ] **典型相關 CI**：$\rho_1$ 以 bootstrap 或 Fisher z 轉換計算 95% CI 的流程與重抽樣次數。
* [ ] **評估協定**：交叉驗證切法、種子數（建議 ≥5）、指標（Macro-F1、AUROC 若適用）、報告平均±標準誤。
* [ ] **運算環境**：硬體（CPU/GPU）、主要套件版本、執行時間量級。
* [ ] **可重現性**：亂數種子、config 檔、腳本（命令列範例）、結果目錄結構。

# 必備實驗（支撐「失效條件 + 診斷流程」）

* [ ] **E1｜零相關基線（Null）**：合成資料保證 $I(X;Y)=0$，量測 HSIC/dCor 之 p 值、$\rho_1$ 與 Macro-F1 應貼近隨機並顯著不變。
  **驗收**：p≥0.05；$\rho_1$ 95% CI 含 0；F1 ≈ 隨機基線。
* [ ] **E2｜互資訊掃描（MI sweep）**：由 0 緩升至可辨識區，觀察 $\rho_1$ 與下游 F1 是否出現同步「相依→提升」的轉折。
  **驗收**：在低 MI 區段仍 No-Go；僅高 MI 區段出現顯著相關。
* [ ] **E3｜對齊破壞（Alignment ablation）**：逐步打亂跨視角配對（0→100%），檢視指標是否隨對齊惡化而崩潰。
  **驗收**：小幅打亂即導致 $\rho_1$ 與 F1 急降→標示敏感區。
* [ ] **E4｜訊噪比掃描（SNR sweep）**：固定 MI，逐步加噪；檢查對噪聲的敏感度與失效邊界。
  **驗收**：標出 SNR 臨界值以下全面 No-Go。
* [ ] **E5｜樣本數學習曲線**：N 由小到大（例如 100→…→10k），報告 $\rho_1$／F1 是否隨 N 增長而仍貼近 0／隨機。
  **驗收**：在廣域 N 區間仍無改善→強化「不適用」結論。
* [ ] **E6｜方法家族一致性**：CCA vs Poly-CCA vs MG-TCCA（含合理超參數網格）。
  **驗收**：三者同趨勢→排除「只是不會調」的質疑。
* [ ] **E7｜診斷流程示範**：以「HSIC/置換→$\rho_1$ CI→學習曲線」串接示例，從輸入到決策（No-Go）一次跑通。
  **驗收**：流程圖 + 對應結果頁，形成可操作指南。

# 推薦擴充實驗（加分但不必全做）

* [ ] **E8｜真實資料子集測試**：至少 1–2 個公開資料（或你現有資料）的子集，複現 No-Go。
* [ ] **E9｜前處理退化測試**：錯誤前處理（錯位、全局置中不當）造成的假相關／零相關對照。
* [ ] **E10｜下游替代路線**：單視角強基線（LR/XGBoost/Conv1D）或監督式 Transformer；證明「換路線才有效」。
* [ ] **E11｜計算成本對照**：No-Go 區域下，CCA 系列的成本 > 收益的量化證據（時間、記憶體）。
* [ ] **E12｜跨資料機制的反例族**：加性噪聲、非線性扭曲、稀疏交互等多機制下同樣失效。

# 圖表清單（建議檔名＋簡短說明）

* [ ] **Fig1\_failure\_map.png**：**失效區域圖**（SNR×Alignment 或 MI×N），色彩為 $\rho_1$ 或 Macro-F1；標出 No-Go 區塊與臨界線。
* [ ] **Fig2\_diagnostic\_pipeline.pdf**：**診斷流程圖**：HSIC/置換 → $\rho_1$ CI → 學習曲線 → 決策（Go/No-Go）。
* [ ] **Fig3\_mi\_sweep\_curves.png**：MI 掃描的 $\rho_1$ 與 F1 曲線（均值±標準誤），顯示低 MI 區無提升。
* [ ] **Fig4\_alignment\_ablation.png**：對齊破壞率 vs $\rho_1$、F1 折線。
* [ ] **Fig5\_snr\_sweep.png**：SNR 掃描曲線，標出臨界 SNR。
* [ ] **Fig6\_learning\_curves.png**：樣本數學習曲線（N vs F1／$\rho_1$）。
* [ ] **Fig7\_method\_family\_compare.png**：CCA／Poly-CCA／MG-TCCA 在相同設定下的並列條形圖（或多曲線）。
* [ ] **Fig8\_null\_perm\_tests.pdf**：HSIC/dCor 的置換分佈直方圖＋實測統計量位置與 p 值。
* [ ] **Tab1\_settings\_summary.csv**：所有設定與超參數表（可機讀），便於重現。
* [ ] **Tab2\_results\_aggregate.csv**：核心指標彙總（均值、標準誤、CI、顯著性標記）。
* [ ] **Supp\_FigA\_tsne\_umap.png（選）**：CCA 表徵與原始特徵的可視化（t-SNE/UMAP）對照，展示無可分性。

# 報告與開源（Artifact）

* [ ] **一鍵重現腳本**：`bash run_all.sh`（含實驗矩陣與隨機種子輪替）。
* [ ] **配置檔**：`configs/*.yaml`（資料機制、MI/SNR/Alignment、model 超參數）。
* [ ] **統計工具**：`stats/hisc_perm.py`、`stats/fisher_ci.py`。
* [ ] **結果卡（Result Cards）**：每次實驗輸出 JSON/CSV 與簡報化摘要（指標、顯著性、No-Go 判斷）。
* [ ] **公開倉庫說明**：README（環境、數據產生器、重現步驟、圖表生成）。

# 寫作對位（稿內放置位置）

* [ ] Methods：補「資料生成／擾動機制」、「檢定流程」與「CI 計算」細節。
* [ ] Results：依 E1–E7 的順序呈現（由 Null → 逐步增加可辨識度），每節含小結與 No-Go 判準。
* [ ] Discussion：整理必要條件、臨界區、威脅效度（外部效度、前處理依賴性）與限制。
* [ ] Appendix：更多反例族、完整超參數表與額外圖表、開源資訊。

---

需要的話，我可以直接幫你把**圖表產生腳本模板**（MI/SNR/Alignment 掃描、HSIC 置換、$\rho_1$ CI、學習曲線）與**結果彙總表頭**生出來，放到你的專案結構中。
